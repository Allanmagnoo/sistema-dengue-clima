# ü¶ü Sistema Dengue-Clima: Data Lakehouse Epidemiol√≥gico

> **Status:** Em Migra√ß√£o para Google Cloud Platform (GCP) ÔøΩ
> **Stack:** Python, Dataform (SQLX), BigQuery, Cloud Composer (Airflow), Vertex AI, Looker Studio.

## 1. Vis√£o do Projeto (Business Case)

O **Sistema Dengue-Clima** √© uma plataforma de Engenharia de Dados projetada para correlacionar dados epidemiol√≥gicos (Dengue, Zika) com dados clim√°ticos (Chuva, Temperatura). O objetivo √© fornecer uma base de dados anal√≠tica (Gold Layer) para prever surtos de arboviroses baseados em padr√µes meteorol√≥gicos, utilizando uma arquitetura moderna na nuvem.

**Fontes de Dados:**

1. **InfoDengue API** (Dados epidemiol√≥gicos semanais).
    * Hist√≥rico: √öltimos 10 anos.
    * Granularidade: Munic√≠pio/Semana.
2. **INMET API** (Dados meteorol√≥gicos hor√°rios/di√°rios).
    * Vari√°veis: Temperatura, Precipita√ß√£o, Umidade.
    * Hist√≥rico: Alinhado com dados epidemiol√≥gicos.
3. **IBGE API** (Dados Demogr√°ficos e Geogr√°ficos).
    * Popula√ß√£o Anual (para c√°lculo de incid√™ncia).
    * Malha Geogr√°fica (Lat/Long).

---

## 2. Escopo e Objetivos

O escopo do projeto √© construir um pipeline de dados ponta a ponta, desde a ingest√£o de dados brutos at√© a camada de agrega√ß√£o, pronta para consumo por ferramentas de Business Intelligence e Machine Learning.

**Objetivos:**
* **Ingest√£o Automatizada:** Coletar dados de forma programada e confi√°vel.
* **Arquitetura Lakehouse:** Implementar as camadas Bronze, Silver e Gold no BigQuery.
* **Qualidade de Dados:** Garantir que os dados sejam limpos, consistentes e prontos para an√°lise usando Dataform Assertions.
* **Escalabilidade:** Utilizar servi√ßos serverless do GCP para suportar grandes volumes de dados.
* **An√°lise de Dados:** Permitir a correla√ß√£o entre dados de dengue e clima para gerar insights via Looker Studio.

---

## 3. Arquitetura (GCP)

A arquitetura do projeto foi migrada da AWS para o Google Cloud Platform para aproveitar recursos nativos de Big Data e ML.

### üìä **Bronze Layer** (Raw Data)
* **Armazenamento:** Google Cloud Storage (GCS) / BigQuery (External Tables)
* **Formato:** JSON/CSV originais
* **Processo:** Ingest√£o via Cloud Functions ou Cloud Composer (Airflow)

### üîÑ **Silver Layer** (Refined Data)
* **Armazenamento:** BigQuery (Native Tables)
* **Ferramenta de Transforma√ß√£o:** Dataform (SQLX)
* **Processos:**
    * Limpeza de dados
    * Padroniza√ß√£o de tipos
    * Deduplica√ß√£o
    * Enriquecimento com dados geogr√°ficos

### üèÜ **Gold Layer** (Analytics Ready)
* **Armazenamento:** BigQuery
* **Ferramenta de Transforma√ß√£o:** Dataform (SQLX)
* **Modelos:**
    * Marts dimensionais (Star Schema)
    * Tabelas agregadas para dashboards
* **ML Integration:** Vertex AI / BigQuery ML para previs√µes de surtos

### üìà **Visualiza√ß√£o**
* **Ferramenta:** Looker Studio
* **Conex√£o:** Direta com BigQuery

---

## 4. Justificativa da Migra√ß√£o (AWS ‚Üí GCP)

A infraestrutura foi migrada da AWS para o GCP visando otimiza√ß√£o de custos e integra√ß√£o facilitada de ferramentas de dados.

* **Integra√ß√£o Nativa:** O uso do **Dataform** integrado ao BigQuery simplifica drasticamente a gest√£o de depend√™ncias e transforma√ß√µes SQL, substituindo scripts complexos em Python/Glue.
* **Serverless First:** O BigQuery oferece uma capacidade de processamento serverless que elimina a necessidade de gerenciamento de clusters (como no EMR/Glue), reduzindo o overhead operacional.
* **Machine Learning:** A integra√ß√£o direta do BigQuery com o **Vertex AI** facilita a cria√ß√£o e deploy de modelos preditivos sem movimenta√ß√£o excessiva de dados.
* **Hist√≥rico:** A vers√£o anterior do projeto utilizava AWS S3, Glue e Athena. Essa experi√™ncia serviu de base para a modelagem atual, mas a stack GCP provou-se mais √°gil para este caso de uso espec√≠fico.

---

## 5. Requisitos de Configura√ß√£o (GCP)

Para executar este projeto no ambiente GCP, s√£o necess√°rios:

1. **Conta Google Cloud:**
   * Projeto ativo com billing habilitado.
   * APIs habilitadas: BigQuery API, Dataform API, Cloud Storage API, Vertex AI API.

2. **Ferramentas Locais:**
   * [Google Cloud SDK (gcloud)](https://cloud.google.com/sdk/docs/install)
   * [Dataform CLI](https://cloud.google.com/dataform/docs/use-dataform-cli) (opcional, para dev local)
   * Python 3.9+

3. **Permiss√µes (IAM):**
   * O usu√°rio ou Service Account deve ter permiss√µes de `BigQuery Data Editor`, `BigQuery Job User` e `Dataform Editor`.

---

## 6. Guia de Implanta√ß√£o

### Configura√ß√£o Inicial

1. **Autentica√ß√£o:**
   ```bash
   gcloud auth application-default login
   gcloud config set project SEU_PROJETO_GCP
   ```

2. **Setup do Dataform:**
   * Navegue at√© a pasta `etl_project`.
   * Configure o arquivo `dataform.json` com o ID do seu projeto GCP.
   * Instale as depend√™ncias:
     ```bash
     npm install
     ```

3. **Execu√ß√£o do Pipeline (Manual):**
   ```bash
   dataform run
   ```

### Deploy Autom√°tico

O deploy cont√≠nuo √© gerenciado via reposit√≥rio conectado ao Dataform no console do GCP.

1. Conecte o reposit√≥rio Git ao Dataform no Console GCP.
2. Crie um "Release Configuration" apontando para a branch `main`.
3. Crie um "Workflow Configuration" para agendar as execu√ß√µes (ex: Di√°rio √†s 06:00 UTC).

---

## 7. Estrutura do Projeto (Atualizada)

```
sistema-dengue-clima/
‚îú‚îÄ‚îÄ etl_project/                 # Projeto Dataform (Novo Core ETL)
‚îÇ   ‚îú‚îÄ‚îÄ 01-bronze/              # Declara√ß√µes de fontes
‚îÇ   ‚îú‚îÄ‚îÄ 02-silver/              # Transforma√ß√µes intermedi√°rias
‚îÇ   ‚îú‚îÄ‚îÄ 03-gold/                # Modelos finais
‚îÇ   ‚îú‚îÄ‚îÄ assertions/             # Testes de qualidade de dados
‚îÇ   ‚îú‚îÄ‚îÄ dataform.json           # Configura√ß√£o do Dataform
‚îÇ   ‚îî‚îÄ‚îÄ package.json            # Depend√™ncias JS
‚îú‚îÄ‚îÄ src/                        # Scripts Python (Legado/Auxiliar)
‚îÇ   ‚îú‚îÄ‚îÄ jobs/                   # Antigos scripts ETL (Refer√™ncia)
‚îÇ   ‚îî‚îÄ‚îÄ app/                    # Aplica√ß√£o Streamlit
‚îú‚îÄ‚îÄ docs/                       # Documenta√ß√£o
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

---

## 8. Equipe e Contatos

* **Desenvolvedor Principal:** Allan Magno
* **Contato:** <allanmagno@gmail.com>
* **GitHub:** [https://github.com/Allanmagnoo](https://github.com/Allanmagnoo)
* **Suporte GCP:** Para quest√µes relacionadas √† infraestrutura GCP, abra uma issue neste reposit√≥rio com a tag `gcp-infra`.
