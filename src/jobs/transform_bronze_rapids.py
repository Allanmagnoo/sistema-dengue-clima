#!/usr/bin/env python3
"""
Script de Transforma√ß√£o Bronze com Rapids (cuDF)
=================================================

Este script demonstra o processamento de m√∫ltiplos arquivos CSV
da camada Bronze usando acelera√ß√£o GPU com Rapids/cuDF.

Funcionalidades:
- Leitura paralela de m√∫ltiplos arquivos CSV
- Transforma√ß√µes e limpeza de dados na GPU
- Agrega√ß√µes e an√°lises estat√≠sticas
- Benchmark de performance
- Gera√ß√£o de relat√≥rios

Autor: Eco-Sentinel Team
Data: 2025-11-29
"""

import cudf
import os
import glob
import sys
import time
from pathlib import Path
from typing import List, Dict, Tuple
import warnings

warnings.filterwarnings('ignore')


class BronzeRapidsProcessor:
    """Processador de dados Bronze usando Rapids/cuDF"""
    
    def __init__(self, base_path: str = None):
        """
        Inicializa o processador
        
        Args:
            base_path: Caminho base para os dados Bronze
        """
        if base_path is None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(script_dir))
            base_path = os.path.join(
                project_root, "data", "bronze", "infodengue", 
                "municipios", "disease=dengue", "year=2024"
            )
        
        self.base_path = base_path
        self.stats = {}
        
    def discover_files(self, limit: int = None) -> List[str]:
        """
        Descobre arquivos CSV dispon√≠veis
        
        Args:
            limit: Limite de arquivos para processar (None = todos)
            
        Returns:
            Lista de caminhos dos arquivos
        """
        pattern = os.path.join(self.base_path, "*.csv")
        files = sorted(glob.glob(pattern))
        
        if limit:
            files = files[:limit]
            
        print(f"üìÅ Arquivos descobertos: {len(files)}")
        return files
    
    def read_single_file(self, filepath: str) -> cudf.DataFrame:
        """
        L√™ um arquivo CSV individual
        
        Args:
            filepath: Caminho do arquivo
            
        Returns:
            DataFrame cuDF
        """
        try:
            df = cudf.read_csv(filepath)
            return df
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao ler {os.path.basename(filepath)}: {e}")
            return None
    
    def read_multiple_files(self, files: List[str], verbose: bool = True) -> cudf.DataFrame:
        """
        L√™ m√∫ltiplos arquivos e concatena
        
        Args:
            files: Lista de caminhos de arquivos
            verbose: Mostrar progresso
            
        Returns:
            DataFrame cuDF concatenado
        """
        start_time = time.time()
        
        if verbose:
            print(f"\n‚è≥ Lendo {len(files)} arquivos...")
        
        dfs = []
        for i, filepath in enumerate(files, 1):
            df = self.read_single_file(filepath)
            if df is not None:
                # Adiciona coluna com o c√≥digo do munic√≠pio
                municipio_code = os.path.basename(filepath).replace('.csv', '')
                df['municipio_code'] = municipio_code
                dfs.append(df)
                
            if verbose and i % 100 == 0:
                print(f"   Processados {i}/{len(files)} arquivos...")
        
        # Concatena todos os DataFrames
        combined_df = cudf.concat(dfs, ignore_index=True)
        
        elapsed_time = time.time() - start_time
        self.stats['read_time'] = elapsed_time
        self.stats['files_read'] = len(dfs)
        self.stats['total_rows'] = len(combined_df)
        
        if verbose:
            print(f"   ‚úì Leitura conclu√≠da em {elapsed_time:.2f}s")
            print(f"   ‚úì Total de registros: {len(combined_df):,}")
        
        return combined_df
    
    def clean_data(self, df: cudf.DataFrame, verbose: bool = True) -> cudf.DataFrame:
        """
        Limpa e prepara os dados
        
        Args:
            df: DataFrame cuDF
            verbose: Mostrar progresso
            
        Returns:
            DataFrame limpo
        """
        if verbose:
            print(f"\nüßπ Limpando dados...")
        
        start_time = time.time()
        initial_rows = len(df)
        
        # Remove linhas com valores nulos em colunas cr√≠ticas
        critical_cols = ['data_iniSE', 'SE', 'Localidade_id']
        df = df.dropna(subset=critical_cols)
        
        # Converte tipos de dados
        if 'SE' in df.columns:
            df['SE'] = df['SE'].astype('int32')
        
        if 'casos' in df.columns:
            df['casos'] = df['casos'].fillna(0).astype('int32')
            
        if 'casos_est' in df.columns:
            df['casos_est'] = df['casos_est'].fillna(0).astype('float32')
        
        # Remove duplicatas
        df = df.drop_duplicates()
        
        elapsed_time = time.time() - start_time
        rows_removed = initial_rows - len(df)
        
        if verbose:
            print(f"   ‚úì Limpeza conclu√≠da em {elapsed_time:.2f}s")
            print(f"   ‚úì Linhas removidas: {rows_removed:,}")
            print(f"   ‚úì Linhas restantes: {len(df):,}")
        
        return df
    
    def aggregate_data(self, df: cudf.DataFrame, verbose: bool = True) -> Dict:
        """
        Realiza agrega√ß√µes nos dados
        
        Args:
            df: DataFrame cuDF
            verbose: Mostrar progresso
            
        Returns:
            Dicion√°rio com estat√≠sticas agregadas
        """
        if verbose:
            print(f"\nüìä Agregando dados...")
        
        start_time = time.time()
        
        aggregations = {}
        
        # Estat√≠sticas gerais
        if 'casos' in df.columns:
            aggregations['total_casos'] = int(df['casos'].sum())
            aggregations['media_casos'] = float(df['casos'].mean())
            aggregations['max_casos'] = int(df['casos'].max())
            aggregations['min_casos'] = int(df['casos'].min())
        
        # Casos por munic√≠pio
        if 'municipio_code' in df.columns and 'casos' in df.columns:
            casos_por_municipio = df.groupby('municipio_code')['casos'].sum().sort_values(ascending=False)
            # Converte apenas os top 10 para dicion√°rio nativo do Python
            top_10 = casos_por_municipio.head(10)
            aggregations['top_10_municipios'] = {
                str(k): int(v) for k, v in zip(top_10.index.to_arrow().to_pylist(), top_10.to_arrow().to_pylist())
            }
        
        # Casos por semana epidemiol√≥gica
        if 'SE' in df.columns and 'casos' in df.columns:
            casos_por_semana = df.groupby('SE')['casos'].sum().sort_values(ascending=False)
            # Limita a semanas com mais casos
            top_semanas = casos_por_semana.head(20)
            aggregations['casos_por_semana'] = {
                int(k): int(v) for k, v in zip(top_semanas.index.to_arrow().to_pylist(), top_semanas.to_arrow().to_pylist())
            }
        
        # Estat√≠sticas de n√≠vel de alerta
        if 'nivel' in df.columns:
            nivel_counts = df['nivel'].value_counts()
            aggregations['distribuicao_nivel'] = {
                int(k): int(v) for k, v in zip(nivel_counts.index.to_arrow().to_pylist(), nivel_counts.to_arrow().to_pylist())
            }
        
        elapsed_time = time.time() - start_time
        
        if verbose:
            print(f"   ‚úì Agrega√ß√£o conclu√≠da em {elapsed_time:.2f}s")
        
        return aggregations
    
    def generate_report(self, aggregations: Dict, verbose: bool = True):
        """
        Gera relat√≥rio de an√°lise
        
        Args:
            aggregations: Dicion√°rio com agrega√ß√µes
            verbose: Mostrar relat√≥rio
        """
        if not verbose:
            return
        
        print("\n" + "=" * 70)
        print("üìà RELAT√ìRIO DE AN√ÅLISE - DADOS DE DENGUE 2024")
        print("=" * 70)
        
        # Estat√≠sticas Gerais
        if 'total_casos' in aggregations:
            print(f"\nüìä Estat√≠sticas Gerais:")
            print(f"   Total de casos: {aggregations['total_casos']:,}")
            print(f"   M√©dia de casos: {aggregations['media_casos']:.2f}")
            print(f"   M√°ximo: {aggregations['max_casos']:,}")
            print(f"   M√≠nimo: {aggregations['min_casos']:,}")
        
        # Top 10 Munic√≠pios
        if 'top_10_municipios' in aggregations:
            print(f"\nüèÜ Top 10 Munic√≠pios com Mais Casos:")
            for i, (municipio, casos) in enumerate(list(aggregations['top_10_municipios'].items())[:10], 1):
                print(f"   {i:2}. {municipio}: {casos:,} casos")
        
        # Distribui√ß√£o por N√≠vel
        if 'distribuicao_nivel' in aggregations:
            print(f"\n‚ö†Ô∏è  Distribui√ß√£o por N√≠vel de Alerta:")
            for nivel, count in aggregations['distribuicao_nivel'].items():
                print(f"   N√≠vel {nivel}: {count:,} registros")
        
        # Performance
        if self.stats:
            print(f"\n‚ö° Performance:")
            print(f"   Arquivos processados: {self.stats.get('files_read', 0)}")
            print(f"   Tempo de leitura: {self.stats.get('read_time', 0):.2f}s")
            print(f"   Registros totais: {self.stats.get('total_rows', 0):,}")
            
            if self.stats.get('read_time', 0) > 0:
                throughput = self.stats.get('total_rows', 0) / self.stats.get('read_time', 0)
                print(f"   Throughput: {throughput:,.0f} registros/segundo")
        
        print("\n" + "=" * 70)


def main():
    """Fun√ß√£o principal"""
    print("=" * 70)
    print("üöÄ RAPIDS BRONZE PROCESSOR - Processamento GPU Acelerado")
    print("=" * 70)
    print(f"cuDF version: {cudf.__version__}")
    print(f"Python: {sys.version.split()[0]}")
    
    # Inicializa processador
    processor = BronzeRapidsProcessor()
    
    # Descobre arquivos (limite para teste inicial)
    files = processor.discover_files(limit=100)  # Processa 100 arquivos
    
    if not files:
        print("‚ùå Nenhum arquivo encontrado!")
        return
    
    # Processa dados
    try:
        # 1. Leitura
        df = processor.read_multiple_files(files, verbose=True)
        
        # 2. Limpeza
        df_clean = processor.clean_data(df, verbose=True)
        
        # 3. Agrega√ß√£o
        aggregations = processor.aggregate_data(df_clean, verbose=True)
        
        # 4. Relat√≥rio
        processor.generate_report(aggregations, verbose=True)
        
        print("\n‚úÖ Processamento conclu√≠do com sucesso!")
        
    except Exception as e:
        print(f"\n‚ùå Erro durante processamento: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
