"""
An√°lise de Compatibilidade entre Dados INMET e Dengue

Este script analisa a estrutura dos dados e prop√µe solu√ß√µes para criar
uma camada Gold com dados clim√°ticos e de dengue compat√≠veis.
"""
import duckdb
import pandas as pd
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    logger.info("üîç Analisando compatibilidade entre INMET e Dengue")
    
    current_dir = Path(__file__).resolve().parent
    base_dir = current_dir
    
    con = duckdb.connect(database=':memory:')
    
    # 1. An√°lise dos dados INMET Bronze
    logger.info("üìä Analisando dados INMET Bronze...")
    
    inmet_bronze_path = base_dir / "data/bronze/inmet/2024"
    
    # Ler amostra de arquivos INMET
    sample_files = list(inmet_bronze_path.glob("*.CSV"))[:5]
    
    logger.info("Amostra de arquivos INMET:")
    for f in sample_files:
        logger.info(f"  - {f.name}")
        # Extrair metadata do filename
        parts = f.name.split('_')
        if len(parts) >= 5:
            regiao = parts[1]
            uf = parts[2] 
            estacao_id = parts[3]
            nome_estacao = parts[4]
            logger.info(f"    Regi√£o: {regiao}, UF: {uf}, Esta√ß√£o: {estacao_id}, Nome: {nome_estacao}")
    
    # 2. An√°lise da estrutura dos dados Silver existentes
    logger.info("üìä Analisando estrutura Silver existente...")
    
    # Verificar se existe mapeamento estacao_geocode
    mapping_path = base_dir / "data/silver/mapping_estacao_geocode.parquet"
    if mapping_path.exists():
        con.execute(f"CREATE VIEW mapping_estacao_geocode AS SELECT * FROM read_parquet('{mapping_path}')")
        mapping_count = con.execute("SELECT COUNT(*) FROM mapping_estacao_geocode").fetchone()[0]
        logger.info(f"‚úÖ Mapeamento estacao_geocode encontrado: {mapping_count} registros")
        
        # Mostrar amostra do mapeamento
        sample_mapping = con.execute("SELECT * FROM mapping_estacao_geocode LIMIT 5").fetchdf()
        logger.info("Amostra do mapeamento:")
        print(sample_mapping)
    else:
        logger.warning("‚ùå Mapeamento estacao_geocode n√£o encontrado")
    
    # 3. Problemas identificados e solu√ß√µes
    logger.info("üéØ Problemas identificados e solu√ß√µes propostas:")
    
    logger.info("\n1. **Falta de geocode nos dados INMET**")
    logger.info("   Solu√ß√£o: Usar o mapeamento estacao_id ‚Üí geocode j√° criado")
    
    logger.info("\n2. **Dados clim√°ticos com NaN ap√≥s join**")
    logger.info("   Causa: Arquivos INMET com schemas diferentes (colunas faltando)")
    logger.info("   Solu√ß√£o: Usar union_by_name=True ao ler arquivos Parquet")
    
    logger.info("\n3. **Cobertura geogr√°fica limitada**")
    logger.info("   Apenas 373 munic√≠pios com dados clim√°ticos dos 5.570+ munic√≠pios brasileiros")
    logger.info("   Solu√ß√£o: Aceitar limita√ß√£o ou buscar dados de mais esta√ß√µes")
    
    logger.info("\n4. **Desalinhamento temporal**")
    logger.info("   Dados dengue: semanal, Dados clima: di√°rio")
    logger.info("   Solu√ß√£o: Agregar clima para semana epidemiol√≥gica")
    
    # 4. Verificar dados dispon√≠veis
    logger.info("\nüìà Verificando disponibilidade de dados:")
    
    # Contar total de munic√≠pios no DTB
    dtb_path = base_dir / "data/bronze/DTB_2024/RELATORIO_DTB_BRASIL_2024_MUNICIPIOS.xls"
    if dtb_path.exists():
        try:
            df_dtb = pd.read_excel(dtb_path)
            logger.info(f"Total de munic√≠pios no DTB: {len(df_dtb)}")
            
            # Verificar colunas dispon√≠veis
            logger.info(f"Colunas DTB: {list(df_dtb.columns)}")
            
        except Exception as e:
            logger.error(f"Erro ao ler DTB: {e}")
    
    # 5. Propor melhorias na estrutura
    logger.info("\nüí° Propostas de melhoria:")
    
    logger.info("""
    **ESTRUTURA PROPOSTA PARA CAMADA GOLD:**
    
    Tabela: gold_dengue_clima
    - geocode (INT): C√≥digo IBGE do munic√≠pio
    - nome_municipio (VARCHAR): Nome do munic√≠pio  
    - uf (VARCHAR): Sigla da UF
    - data_inicio_semana (DATE): In√≠cio da semana epidemiol√≥gica
    - semana_epidemiologica (INT): Semana no formato YYYYWW
    - ano_epidemiologico (INT): Ano da semana
    - casos_notificados (INT): Casos de dengue notificados
    - casos_estimados (FLOAT): Casos estimados pelo modelo
    - casos_confirmados (INT): Casos confirmados
    - incidencia_100k (FLOAT): Incid√™ncia por 100 mil habitantes
    - nivel_alerta (INT): N√≠vel de alerta (1-4)
    - populacao (FLOAT): Popula√ß√£o do munic√≠pio
    - temperatura_media_semanal (FLOAT): M√©dia de temperatura na semana
    - precipitacao_total_semanal (FLOAT): Soma da precipita√ß√£o na semana
    - umidade_media_semanal (FLOAT): M√©dia da umidade relativa
    - estacao_id (VARCHAR): ID da esta√ß√£o meteorol√≥gica (para refer√™ncia)
    - distancia_estacao_km (FLOAT): Dist√¢ncia aproximada at√© a esta√ß√£o
    
    **CONSIDERA√á√ïES:**
    1. Usar left join para manter todos os munic√≠pios com dados de dengue
    2. Permitir valores NULL para dados clim√°ticos quando n√£o houver esta√ß√£o pr√≥xima
    3. Adicionar flags indicando qualidade/Fonte dos dados clim√°ticos
    4. Documentar limita√ß√µes de cobertura geogr√°fica
    
    **PR√ìXIMOS PASSOS:**
    1. Executar transform_silver_inmet.py para gerar dados Silver
    2. Executar transform_silver_dengue.py para gerar dados Silver  
    3. Verificar qualidade dos dados Silver gerados
    4. Ajustar script Gold para lidar com dados clim√°ticos faltantes
    5. Adicionar an√°lise de dist√¢ncia entre munic√≠pios e esta√ß√µes
    """)
    
    con.close()
    logger.info("‚úÖ An√°lise de compatibilidade conclu√≠da")

if __name__ == "__main__":
    main()