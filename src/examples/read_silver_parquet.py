"""
Exemplo de Leitura de Arquivos Parquet da Camada Silver
-------------------------------------------------------
Este script demonstra como ler e analisar os dados processados na camada Silver
usando duas abordagens: DuckDB (SQL) e Pandas (Python).

Vantagens do Parquet:
1. Colunar: L√™ apenas as colunas necess√°rias (muito mais r√°pido para an√°lises).
2. Compress√£o: Ocupa 1/4 do espa√ßo de um CSV equivalente.
3. Tipagem: Preserva tipos de dados (datas, n√∫meros, nulos).
4. Particionamento: Permite leitura inteligente (ex: ler apenas dados de SP em 2024).

Uso:
    python read_silver_example.py
"""
import duckdb
import pandas as pd
from pathlib import Path
import time
import os

def get_project_root():
    """Retorna o diret√≥rio raiz do projeto."""
    return Path(__file__).resolve().parent.parent.parent

def read_with_duckdb(silver_path):
    """
    L√™ dados usando DuckDB (Recomendado para grandes volumes/SQL).
    """
    print("\n" + "="*50)
    print("ü¶Ü Lendo com DuckDB (Alta Performance & SQL)")
    print("="*50)
    
    con = duckdb.connect(':memory:')
    
    start_time = time.time()
    
    # DuckDB l√™ nativamente a estrutura particionada (hive partitioning)
    # O curinga **/*.parquet varre recursivamente todos os arquivos
    query = f"""
    SELECT 
        uf,
        ano_epidemiologico,
        count(*) as total_registros,
        sum(casos_provaveis) as total_casos,
        avg(temperatura_media) as temp_media
    FROM read_parquet('{silver_path}/**/*.parquet', hive_partitioning=1)
    GROUP BY uf, ano_epidemiologico
    ORDER BY total_casos DESC
    LIMIT 5
    """
    
    try:
        # Tenta executar com nomes de colunas novos (p√≥s-transforma√ß√£o)
        df = con.execute(query.replace("casos_provaveis", "casos_notificados")).df()
    except:
        # Fallback para nomes antigos se a transforma√ß√£o mudou
        try:
            print("‚ö†Ô∏è Tentando colunas alternativas...")
            df = con.execute(f"""
            SELECT 
                uf,
                year_partition as ano,
                count(*) as total_registros
            FROM read_parquet('{silver_path}/**/*.parquet', hive_partitioning=1)
            GROUP BY uf, year_partition
            LIMIT 5
            """).df()
        except Exception as e:
            print(f"‚ùå Erro na query: {e}")
            return

    elapsed = time.time() - start_time
    print(f"‚è±Ô∏è Tempo de execu√ß√£o: {elapsed:.4f} segundos")
    print("\nüìä Resultado (Top 5 Estados por Casos):")
    print(df.to_markdown(index=False))
    
    # Exemplo de filtro eficiente (Pushdown Predicate)
    print("\nüîç Exemplo: Filtrando apenas RJ em 2024...")
    query_filter = f"""
    SELECT geocode, nome_municipio, data_inicio_semana, casos_notificados
    FROM read_parquet('{silver_path}/**/*.parquet', hive_partitioning=1)
    WHERE uf = 'RJ' AND ano_epidemiologico = 2024
    ORDER BY casos_notificados DESC
    LIMIT 5
    """
    print(con.execute(query_filter).df().to_markdown(index=False))

def read_with_pandas(silver_path):
    """
    L√™ dados usando Pandas (Bom para explora√ß√£o interativa e gr√°ficos).
    """
    print("\n" + "="*50)
    print("üêº Lendo com Pandas (An√°lise de Dados Python)")
    print("="*50)
    
    start_time = time.time()
    
    try:
        # Pandas l√™ diret√≥rio particionado se engine='pyarrow' estiver instalado
        # Caso contr√°rio, lemos um arquivo espec√≠fico para demonstra√ß√£o
        df = pd.read_parquet(silver_path, engine='pyarrow')
        
        elapsed = time.time() - start_time
        print(f"‚è±Ô∏è Tempo de leitura (Todo o Dataset): {elapsed:.4f} segundos")
        print(f"üìè Shape: {df.shape}")
        print("\nüìã Primeiras linhas:")
        print(df.head(3).to_markdown(index=False))
        
        print("\nüìâ Estat√≠sticas de Casos:")
        print(df['casos_notificados'].describe())
        
    except Exception as e:
        print(f"‚ö†Ô∏è Leitura direta de pasta falhou ({e}). Lendo arquivos individuais...")
        # Fallback: Listar arquivos e ler um exemplo
        files = list(Path(silver_path).glob("**/*.parquet"))
        if files:
            f = files[0]
            print(f"üìÑ Lendo arquivo exemplo: {f.name}")
            df = pd.read_parquet(f)
            print(df.head().to_markdown())

if __name__ == "__main__":
    root = get_project_root()
    silver_path = root / "data/silver/infodengue"
    
    if not silver_path.exists():
        print(f"‚ùå Diret√≥rio Silver n√£o encontrado: {silver_path}")
    else:
        # Instalar depend√™ncia para markdown se necess√°rio
        try:
            import tabulate
        except ImportError:
            os.system("pip install tabulate > /dev/null 2>&1")
            
        read_with_duckdb(str(silver_path))
        # read_with_pandas(str(silver_path)) # Opcional, DuckDB √© mais r√°pido para demo
