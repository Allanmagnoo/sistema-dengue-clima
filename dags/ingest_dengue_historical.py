
from airflow import DAG
try:
    from airflow.providers.standard.operators.python import PythonOperator
except ImportError:
    from airflow.operators.python_operator import PythonOperator

import logging
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.environ.get("AIRFLOW_HOME", "/opt/airflow"), "src"))

from datetime import datetime, timedelta
from src.connectors.infodengue_api import InfoDengueConnector

logger = logging.getLogger("airflow.task")

# --- CONFIGURA√á√ïES DE NEG√ìCIO ---

# Dicion√°rio com os Geocodes (IBGE 7 d√≠gitos) de todas as Capitais do Brasil
CAPITAIS_BR = {
    'AC': 1200401, # Rio Branco
    'AL': 2704302, # Macei√≥
    'AP': 1600303, # Macap√°
    'AM': 1302603, # Manaus
    'BA': 2927408, # Salvador
    'CE': 2304400, # Fortaleza
    'DF': 5300108, # Bras√≠lia
    'ES': 3205309, # Vit√≥ria
    'GO': 5208707, # Goi√¢nia
    'MA': 2111300, # S√£o Lu√≠s
    'MT': 5103403, # Cuiab√°
    'MS': 5002704, # Campo Grande
    'MG': 3106200, # Belo Horizonte
    'PA': 1501402, # Bel√©m
    'PB': 2507507, # Jo√£o Pessoa
    'PR': 4106902, # Curitiba
    'PE': 2611606, # Recife
    'PI': 2211001, # Teresina
    'RJ': 3304557, # Rio de Janeiro
    'RN': 2408102, # Natal
    'RS': 4314902, # Porto Alegre
    'RO': 1100205, # Porto Velho
    'RR': 1400100, # Boa Vista
    'SC': 4205407, # Florian√≥polis
    'SP': 3550308, # S√£o Paulo
    'SE': 2800308, # Aracaju
    'TO': 1721000  # Palmas
}

# Per√≠odo de interesse (Solicita√ß√£o: 2024 e 2025)
ANOS_HISTORICO = [2024, 2025]

def _ingest_dengue_data(uf: str, geocode: int, year: int, **kwargs):
    """
    Task at√¥mica: Baixa dados de uma Capital para um Ano.
    """
    logger.info(f"üöÄ Iniciando ingest√£o: {uf} (Geo: {geocode}) - Ano {year}")
    
    connector = InfoDengueConnector()
    
    # 1. Busca na API
    try:
        dados = connector.fetch_data(geocode=geocode, year=year, disease="dengue")
        
        # 2. Salva no Data Lake (Bronze)
        if dados:
            connector.save_local(dados, geocode=geocode, year=year, disease="dengue")
        else:
            logger.warning(f"‚ö†Ô∏è API retornou vazio para {uf} em {year}")
            
    except Exception as e:
        logger.error(f"‚ùå Falha cr√≠tica em {uf}: {e}")
        # N√£o damos 'raise' aqui para n√£o parar a DAG inteira; 
        # apenas esta task ficar√° vermelha (Failed) se o Airflow estiver configurado para isso,
        # ou apenas logamos o erro para an√°lise posterior.

with DAG(
    dag_id="01_ingest_dengue_historical",
    start_date=datetime(2023, 1, 1),
    schedule=None, 
    catchup=False,
    tags=["bronze", "ingestion", "dengue", "capitais"],
    max_active_tasks=4, # Importante: Limita a 4 requests simult√¢neos para n√£o bloquear IP
    doc_md="""
    # Ingest√£o Hist√≥rica InfoDengue (Nacional)
    
    Monitoramento das 27 Capitais Brasileiras.
    Destaque: Uso de `max_active_tasks` para respeitar rate limits da API p√∫blica.
    """
) as dag:

    # Gera√ß√£o Din√¢mica de Tasks (27 estados * 2 anos = 54 tasks)
    for uf, geocode in CAPITAIS_BR.items():
        for ano in ANOS_HISTORICO:
            
            task_id = f"get_{uf}_{ano}"
            
            PythonOperator(
                task_id=task_id,
                python_callable=_ingest_dengue_data,
                op_kwargs={
                    "uf": uf,
                    "geocode": geocode,
                    "year": ano
                }
            )