{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîç Valida√ß√£o e Interpreta√ß√£o do Modelo de Dengue\n",
                "\n",
                "Este notebook explica:\n",
                "1. **O que o modelo faz** e para que serve\n",
                "2. **Como confiar nos resultados** (m√©tricas e valida√ß√£o)\n",
                "3. **Visualiza√ß√µes** para confirmar a qualidade\n",
                "\n",
                "---\n",
                "\n",
                "## üìö O que √© este modelo?\n",
                "\n",
                "√â um **modelo de regress√£o** que prev√™ **quantos casos de dengue** ocorrer√£o em um munic√≠pio em uma determinada semana, baseado em:\n",
                "- Dados clim√°ticos (temperatura, precipita√ß√£o)\n",
                "- Hist√≥rico de casos (semanas anteriores)\n",
                "- Caracter√≠sticas do munic√≠pio (popula√ß√£o, regi√£o)\n",
                "\n",
                "### Para que serve?\n",
                "- **Alertas antecipados**: Prever surtos antes que aconte√ßam\n",
                "- **Aloca√ß√£o de recursos**: Saber onde enviar equipes de sa√∫de\n",
                "- **Planejamento**: Preparar hospitais para demanda"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import json\n",
                "from pathlib import Path\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "print(\"‚úÖ Bibliotecas carregadas!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar modelo e dados\n",
                "project_root = Path('..').resolve()\n",
                "\n",
                "model = joblib.load(project_root / 'models/dengue_model.joblib')\n",
                "with open(project_root / 'models/model_metadata.json') as f:\n",
                "    metadata = json.load(f)\n",
                "\n",
                "print(f\"üìä Modelo: {metadata['model_type']}\")\n",
                "print(f\"   R¬≤ no teste: {metadata['metrics']['test']['r2']:.4f}\")\n",
                "print(f\"   MAE no teste: {metadata['metrics']['test']['mae']:.1f} casos\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar dados Gold\n",
                "data_path = project_root / 'data/gold/gold_dengue_clima'\n",
                "parquet_files = list(data_path.rglob('*.parquet'))\n",
                "\n",
                "dfs = []\n",
                "for f in parquet_files:\n",
                "    temp_df = pd.read_parquet(f)\n",
                "    if 'uf' not in temp_df.columns:\n",
                "        parts = [p for p in f.parts if p.startswith('uf=')]\n",
                "        if parts:\n",
                "            temp_df['uf'] = parts[0].replace('uf=', '')\n",
                "    dfs.append(temp_df)\n",
                "\n",
                "df = pd.concat(dfs, ignore_index=True)\n",
                "print(f\"üìÇ Dados carregados: {len(df):,} registros\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìà Como interpretar as m√©tricas?\n",
                "\n",
                "### R¬≤ (Coeficiente de Determina√ß√£o)\n",
                "- **O que √©**: Quanto da varia√ß√£o nos casos o modelo consegue explicar\n",
                "- **Interpreta√ß√£o**:\n",
                "  - `R¬≤ = 0.95` ‚Üí Modelo explica 95% da varia√ß√£o ‚úÖ\n",
                "  - `R¬≤ = 0.50` ‚Üí Modelo explica 50% (m√©dio) ‚ö†Ô∏è\n",
                "  - `R¬≤ < 0.30` ‚Üí Modelo fraco ‚ùå\n",
                "\n",
                "### MAE (Erro Absoluto M√©dio)\n",
                "- **O que √©**: Em m√©dia, quantos casos o modelo erra\n",
                "- **Interpreta√ß√£o**:\n",
                "  - `MAE = 11` ‚Üí Em m√©dia, erra por 11 casos\n",
                "  - Se o munic√≠pio tem 100 casos reais, o modelo prev√™ entre 89-111"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 1: Cross-Validation Temporal\n",
                "\n",
                "**Por que isso √© importante?**\n",
                "\n",
                "Em s√©ries temporais, n√£o podemos usar o futuro para prever o passado. O Cross-Validation Temporal simula isso:\n",
                "- Treina em semanas 1-10, testa na 11\n",
                "- Treina em semanas 1-20, testa na 21\n",
                "- etc.\n",
                "\n",
                "Se o R¬≤ se mant√©m alto em todos os folds, o modelo √© confi√°vel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preparar dados para valida√ß√£o\n",
                "model_df = df.copy()\n",
                "\n",
                "# Criar features de lag\n",
                "model_df = model_df.sort_values(['geocode', 'ano_epidemiologico', 'semana_epidemiologica'])\n",
                "for lag in [1, 2, 3, 4]:\n",
                "    model_df[f'casos_lag{lag}'] = model_df.groupby('geocode')['casos_notificados'].shift(lag)\n",
                "model_df['casos_media_4sem'] = model_df.groupby('geocode')['casos_notificados'].transform(\n",
                "    lambda x: x.shift(1).rolling(4, min_periods=1).mean()\n",
                ")\n",
                "\n",
                "# Encoding\n",
                "model_df['semana_sin'] = np.sin(2 * np.pi * model_df['semana_epidemiologica'] / 53)\n",
                "model_df['semana_cos'] = np.cos(2 * np.pi * model_df['semana_epidemiologica'] / 53)\n",
                "model_df['geocode_hash'] = model_df['geocode'].apply(lambda x: hash(str(x)) % 1000)\n",
                "\n",
                "region_map = {\n",
                "    'AC': 0, 'AM': 0, 'AP': 0, 'PA': 0, 'RO': 0, 'RR': 0, 'TO': 0,\n",
                "    'AL': 1, 'BA': 1, 'CE': 1, 'MA': 1, 'PB': 1, 'PE': 1, 'PI': 1, 'RN': 1, 'SE': 1,\n",
                "    'DF': 2, 'GO': 2, 'MS': 2, 'MT': 2,\n",
                "    'ES': 3, 'MG': 3, 'RJ': 3, 'SP': 3,\n",
                "    'PR': 4, 'RS': 4, 'SC': 4\n",
                "}\n",
                "model_df['regiao'] = model_df['uf'].map(region_map).fillna(-1).astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-validation temporal\n",
                "features = metadata['features']\n",
                "clean_df = model_df[features + ['casos_notificados']].dropna()\n",
                "\n",
                "X = clean_df[features]\n",
                "y = clean_df['casos_notificados']\n",
                "\n",
                "# 5 splits temporais\n",
                "tscv = TimeSeriesSplit(n_splits=5)\n",
                "\n",
                "scores = []\n",
                "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
                "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
                "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
                "    \n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    r2 = r2_score(y_test, y_pred)\n",
                "    mae = mean_absolute_error(y_test, y_pred)\n",
                "    scores.append({'fold': fold, 'r2': r2, 'mae': mae})\n",
                "    print(f\"Fold {fold}: R¬≤ = {r2:.4f}, MAE = {mae:.1f}\")\n",
                "\n",
                "scores_df = pd.DataFrame(scores)\n",
                "print(f\"\\nüìä M√©dia: R¬≤ = {scores_df['r2'].mean():.4f} (¬±{scores_df['r2'].std():.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Gr√°fico de Cross-Validation\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "\n",
                "bars = ax.bar(scores_df['fold'], scores_df['r2'], color='steelblue', edgecolor='white')\n",
                "ax.axhline(scores_df['r2'].mean(), color='red', linestyle='--', lw=2, label=f\"M√©dia: {scores_df['r2'].mean():.3f}\")\n",
                "ax.axhline(0.9, color='green', linestyle=':', lw=2, alpha=0.7, label='Limite bom (0.9)')\n",
                "\n",
                "ax.set_xlabel('Fold (Divis√£o Temporal)', fontsize=12)\n",
                "ax.set_ylabel('R¬≤ Score', fontsize=12)\n",
                "ax.set_title('‚úÖ Cross-Validation Temporal (5 Folds)', fontsize=14)\n",
                "ax.set_ylim(0, 1)\n",
                "ax.legend()\n",
                "\n",
                "# Adicionar valores nas barras\n",
                "for bar, score in zip(bars, scores_df['r2']):\n",
                "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
                "            f'{score:.3f}', ha='center', fontsize=11)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
                "if scores_df['r2'].mean() > 0.9:\n",
                "    print(\"   ‚úÖ Modelo EXCELENTE! R¬≤ consistente acima de 0.9 em todos os folds.\")\n",
                "elif scores_df['r2'].mean() > 0.7:\n",
                "    print(\"   ‚ö†Ô∏è Modelo BOM, mas com espa√ßo para melhoria.\")\n",
                "else:\n",
                "    print(\"   ‚ùå Modelo precisa de mais trabalho.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 2: Real vs Predito\n",
                "\n",
                "O gr√°fico ideal mostra pontos alinhados na diagonal (y = x)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Retreinar com todos os dados para visualiza√ß√£o\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "# Calcular m√©tricas\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "mae = mean_absolute_error(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Gr√°fico: Real vs Predito\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# Scatter plot\n",
                "ax1 = axes[0]\n",
                "ax1.scatter(y_test, y_pred, alpha=0.3, s=10, c='steelblue')\n",
                "max_val = max(y_test.max(), y_pred.max())\n",
                "ax1.plot([0, max_val], [0, max_val], 'r-', lw=3, label='Ideal (predito = real)')\n",
                "ax1.set_xlabel('Casos Reais', fontsize=12)\n",
                "ax1.set_ylabel('Casos Preditos', fontsize=12)\n",
                "ax1.set_title(f'Real vs Predito (R¬≤ = {r2:.3f})', fontsize=14)\n",
                "ax1.legend(fontsize=11)\n",
                "\n",
                "# Zoom em casos menores\n",
                "ax2 = axes[1]\n",
                "mask = (y_test < 500) & (y_pred.flatten() < 500)\n",
                "ax2.scatter(y_test[mask], y_pred[mask], alpha=0.3, s=15, c='coral')\n",
                "ax2.plot([0, 500], [0, 500], 'r-', lw=3, label='Ideal')\n",
                "ax2.set_xlabel('Casos Reais', fontsize=12)\n",
                "ax2.set_ylabel('Casos Preditos', fontsize=12)\n",
                "ax2.set_title('Zoom: Casos < 500 (maioria)', fontsize=14)\n",
                "ax2.legend(fontsize=11)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
                "print(\"   - Quanto mais alinhados √† linha vermelha, melhor o modelo\")\n",
                "print(f\"   - R¬≤ = {r2:.3f} ‚Üí O modelo explica {r2*100:.0f}% da varia√ß√£o nos casos\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 3: Distribui√ß√£o dos Erros\n",
                "\n",
                "Os erros devem estar centrados em zero (sem vi√©s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular erros\n",
                "errors = y_test.values - y_pred\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Histograma\n",
                "ax1 = axes[0]\n",
                "ax1.hist(errors, bins=50, color='steelblue', edgecolor='white', alpha=0.7)\n",
                "ax1.axvline(0, color='red', linestyle='--', lw=2, label='Zero (sem erro)')\n",
                "ax1.axvline(errors.mean(), color='orange', linestyle='-', lw=2, label=f'M√©dia: {errors.mean():.1f}')\n",
                "ax1.set_xlabel('Erro (Real - Predito)', fontsize=12)\n",
                "ax1.set_ylabel('Frequ√™ncia', fontsize=12)\n",
                "ax1.set_title('Distribui√ß√£o dos Erros', fontsize=14)\n",
                "ax1.legend()\n",
                "\n",
                "# Boxplot por regi√£o\n",
                "ax2 = axes[1]\n",
                "error_df = pd.DataFrame({'erro': errors, 'regiao': X_test['regiao'].values})\n",
                "region_names = {0: 'Norte', 1: 'Nordeste', 2: 'C-Oeste', 3: 'Sudeste', 4: 'Sul'}\n",
                "error_df['regiao_nome'] = error_df['regiao'].map(region_names)\n",
                "sns.boxplot(data=error_df, x='regiao_nome', y='erro', ax=ax2, palette='Set2')\n",
                "ax2.axhline(0, color='red', linestyle='--', lw=2)\n",
                "ax2.set_xlabel('Regi√£o', fontsize=12)\n",
                "ax2.set_ylabel('Erro', fontsize=12)\n",
                "ax2.set_title('Erro por Regi√£o', fontsize=14)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüí° INTERPRETA√á√ÉO:\")\n",
                "print(f\"   - M√©dia do erro: {errors.mean():.2f} (quanto mais perto de 0, melhor)\")\n",
                "print(f\"   - Desvio padr√£o: {errors.std():.2f}\")\n",
                "if abs(errors.mean()) < 5:\n",
                "    print(\"   ‚úÖ Modelo sem vi√©s significativo!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 4: Feature Importance\n",
                "\n",
                "Quais vari√°veis o modelo mais usa para prever?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': features,\n",
                "    'Import√¢ncia': model.feature_importances_\n",
                "}).sort_values('Import√¢ncia', ascending=True)\n",
                "\n",
                "# Categorizar features\n",
                "def categorize(f):\n",
                "    if 'casos' in f:\n",
                "        return 'Casos (lag)'\n",
                "    elif 'inmet' in f:\n",
                "        return 'Clima'\n",
                "    elif 'semana' in f or 'ano' in f:\n",
                "        return 'Temporal'\n",
                "    else:\n",
                "        return 'Geogr√°fico'\n",
                "\n",
                "importance_df['Categoria'] = importance_df['Feature'].apply(categorize)\n",
                "\n",
                "# Cores por categoria\n",
                "color_map = {'Casos (lag)': '#2ecc71', 'Clima': '#3498db', 'Temporal': '#f1c40f', 'Geogr√°fico': '#e74c3c'}\n",
                "colors = [color_map[cat] for cat in importance_df['Categoria']]\n",
                "\n",
                "plt.figure(figsize=(12, 8))\n",
                "bars = plt.barh(importance_df['Feature'], importance_df['Import√¢ncia'], color=colors)\n",
                "plt.xlabel('Import√¢ncia', fontsize=12)\n",
                "plt.title('üéØ Import√¢ncia das Features', fontsize=14)\n",
                "\n",
                "# Legenda\n",
                "from matplotlib.patches import Patch\n",
                "legend_elements = [Patch(facecolor=color_map[k], label=k) for k in color_map]\n",
                "plt.legend(handles=legend_elements, loc='lower right', fontsize=11)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Resumo por categoria\n",
                "print(\"\\nüìä Import√¢ncia por Categoria:\")\n",
                "cat_importance = importance_df.groupby('Categoria')['Import√¢ncia'].sum().sort_values(ascending=False)\n",
                "for cat, imp in cat_importance.items():\n",
                "    print(f\"   {cat}: {imp*100:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 5: An√°lise Temporal\n",
                "\n",
                "O modelo funciona bem ao longo do tempo?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Adicionar predi√ß√µes ao dataframe de teste\n",
                "test_df = clean_df.iloc[X_test.index].copy()\n",
                "test_df['predito'] = y_pred\n",
                "test_df['erro'] = test_df['casos_notificados'] - test_df['predito']\n",
                "\n",
                "# Agregar por semana\n",
                "weekly = test_df.groupby('semana_epidemiologica').agg({\n",
                "    'casos_notificados': 'sum',\n",
                "    'predito': 'sum',\n",
                "    'erro': 'mean'\n",
                "}).reset_index()\n",
                "\n",
                "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
                "\n",
                "# Casos reais vs preditos por semana\n",
                "ax1 = axes[0]\n",
                "ax1.plot(weekly['semana_epidemiologica'], weekly['casos_notificados'], \n",
                "         'b-', lw=2, marker='o', label='Real')\n",
                "ax1.plot(weekly['semana_epidemiologica'], weekly['predito'], \n",
                "         'r--', lw=2, marker='s', label='Predito')\n",
                "ax1.set_xlabel('Semana Epidemiol√≥gica', fontsize=12)\n",
                "ax1.set_ylabel('Total de Casos', fontsize=12)\n",
                "ax1.set_title('Casos Reais vs Preditos por Semana', fontsize=14)\n",
                "ax1.legend(fontsize=11)\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Erro por semana\n",
                "ax2 = axes[1]\n",
                "colors = ['green' if e < 0 else 'red' for e in weekly['erro']]\n",
                "ax2.bar(weekly['semana_epidemiologica'], weekly['erro'], color=colors, alpha=0.7)\n",
                "ax2.axhline(0, color='black', linestyle='-', lw=1)\n",
                "ax2.set_xlabel('Semana Epidemiol√≥gica', fontsize=12)\n",
                "ax2.set_ylabel('Erro M√©dio', fontsize=12)\n",
                "ax2.set_title('Erro M√©dio por Semana (verde = subestimou, vermelho = superestimou)', fontsize=14)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ Valida√ß√£o 6: Exemplos Concretos\n",
                "\n",
                "Vamos ver casos espec√≠ficos para entender melhor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Adicionar nome do munic√≠pio se dispon√≠vel\n",
                "if 'nome_municipio' in model_df.columns:\n",
                "    test_df = test_df.merge(\n",
                "        model_df[['geocode', 'nome_municipio', 'uf']].drop_duplicates(),\n",
                "        left_on='geocode_hash', right_on=model_df['geocode'].apply(lambda x: hash(str(x)) % 1000),\n",
                "        how='left'\n",
                "    )\n",
                "\n",
                "# Top 10 melhores predi√ß√µes (menor erro percentual)\n",
                "test_df['erro_pct'] = np.abs(test_df['erro']) / (test_df['casos_notificados'] + 1) * 100\n",
                "\n",
                "print(\"‚úÖ TOP 10 - Melhores Predi√ß√µes (menor erro):\")\n",
                "best = test_df.nsmallest(10, 'erro_pct')[['casos_notificados', 'predito', 'erro']]\n",
                "best.columns = ['Casos Reais', 'Predi√ß√£o', 'Erro']\n",
                "print(best.to_string(index=False))\n",
                "\n",
                "print(\"\\n‚ùå TOP 10 - Piores Predi√ß√µes (maior erro):\")\n",
                "worst = test_df[test_df['casos_notificados'] > 50].nlargest(10, 'erro_pct')[['casos_notificados', 'predito', 'erro']]\n",
                "worst.columns = ['Casos Reais', 'Predi√ß√£o', 'Erro']\n",
                "print(worst.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìã Resumo da Valida√ß√£o\n",
                "\n",
                "Execute a c√©lula abaixo para ver um resumo completo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"üìã RESUMO DA VALIDA√á√ÉO\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\\nüéØ Performance Geral:\")\n",
                "print(f\"   R¬≤ = {r2:.4f} ({r2*100:.1f}% da varia√ß√£o explicada)\")\n",
                "print(f\"   MAE = {mae:.1f} casos de erro m√©dio\")\n",
                "\n",
                "print(f\"\\n‚úÖ Cross-Validation:\")\n",
                "print(f\"   M√©dia R¬≤ = {scores_df['r2'].mean():.4f} (¬±{scores_df['r2'].std():.4f})\")\n",
                "print(f\"   Modelo est√°vel ao longo do tempo: {'SIM ‚úÖ' if scores_df['r2'].std() < 0.1 else 'N√ÉO ‚ö†Ô∏è'}\")\n",
                "\n",
                "print(f\"\\nüìä Vi√©s:\")\n",
                "print(f\"   Erro m√©dio = {errors.mean():.2f}\")\n",
                "print(f\"   Modelo sem vi√©s: {'SIM ‚úÖ' if abs(errors.mean()) < 5 else 'N√ÉO ‚ö†Ô∏è'}\")\n",
                "\n",
                "print(f\"\\nüîë Features mais importantes:\")\n",
                "for _, row in importance_df.tail(3).iloc[::-1].iterrows():\n",
                "    print(f\"   ‚Ä¢ {row['Feature']}: {row['Import√¢ncia']*100:.1f}%\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "if r2 > 0.9 and scores_df['r2'].std() < 0.1:\n",
                "    print(\"üèÜ CONCLUS√ÉO: Modelo CONFI√ÅVEL para uso em produ√ß√£o!\")\n",
                "elif r2 > 0.7:\n",
                "    print(\"‚ö†Ô∏è CONCLUS√ÉO: Modelo BOM, mas pode ser melhorado.\")\n",
                "else:\n",
                "    print(\"‚ùå CONCLUS√ÉO: Modelo precisa de mais trabalho.\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}